{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anima-iwr/SU_HD_Workshop/blob/main/Introduction_to_Causal_Inference_and_ITE_Estimation_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPKe5qGxJ8-5"
      },
      "source": [
        "# *2nd Sorbonne-Heidelberg Workshop on AI in medicine: Machine Learning for multi-modal data*\n",
        "---\n",
        "---\n",
        "MIISM Group of Prof. Hesser\n",
        "\n",
        "contact: andrei.sirazitdinov@medma.uni-heidelberg.de or marcus.buchwald@medma.uni-heidelberg.de\n",
        "\n",
        "---\n",
        "\n",
        "*The seperate section are collapsed: Uncollapse the sections by clicking on the \">\" logo left to the section title.*\n",
        "\n",
        "\n",
        "### **First step**:\n",
        "#### **please copy the Google Colab File (\"*File*\" -> \"*Save Copy in Drive*\"), than open this copy before starting to work on it.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB8rOrUnu2fR"
      },
      "source": [
        "# What is Causal Inference?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys5rfHCQ--tw"
      },
      "source": [
        "Have you ever heard the phrase \"correlation is not causation\"? In this workshop, we'll explore the deeper meaning behind that idea and why it's important to distinguish between the two.\n",
        "\n",
        "This brings us to the concept of causal inference — a field dedicated to **uncovering causal relationships between variables by making specific causal assumptions**. Understanding this helps us move beyond simply observing correlations to identifying cause-and-effect dynamics.\n",
        "\n",
        "As this is a workshop on articificial intelligence in medicine, let's first take a look on it from the machine learning perspective.\n",
        "Building on standard machine learning concepts, we use input data $X$ (also called covariate features, such as patient information) and output data $Y$ (the outcome, like a health result). However, in causal inference (especially in Causal Treatment Effect Estimation), we also introduce a new element: $T$, or treatment, which represents the action taken on a patient. For instance, $T$ could refer to a specific medical intervention. These relationships between $X$, $T$, and $Y$ are often depicted using a directed acyclic graph (DAG), which illustrates complex causal structures.\n",
        "\n",
        "While correlation describes the statistical relationship between variables, causality seeks to answer more fundamental questions like:\n",
        "\n",
        "- **What happens to other variables if we intervene on a variable?**\n",
        "- **What is the effect of one variable on another?**\n",
        "\n",
        "\n",
        "### Why Is Causal Inference Important?\n",
        "\n",
        "Causal inference is essential in many fields like economics, medicine, public policy, and marketing, where decision-makers need to understand the impact of actions, treatments, or policies. For example:\n",
        "\n",
        "- In healthcare, causal inference helps determine the effect of a drug on patient recovery.\n",
        "- In economics, it can measure the impact of a policy change on unemployment rates.\n",
        "- In business, it assists in understanding the effect of marketing campaigns on sales.\n",
        "\n",
        "### How can you measure causal effects?\n",
        "\n",
        "In general, the most reliable way to measure the causal effect of an action (referred to as a \"treatment\") on a system of interest (the \"outcome\") is through a randomized controlled trial (RCT).\n",
        "\n",
        "However, conducting such controlled experiments is often impractical or unethical. In these situations, analysts must rely on observational data, i.e. data collected without the benefit of a controlled experimental setup.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgSdwi-ku7rT"
      },
      "source": [
        "# Challenges with causal inference for observational data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdgNvsJ-gbzE"
      },
      "source": [
        "The challenge with observational data is that the observed effects can be influenced by various factors, including both genuine causal relationships and unrelated correlations (also known as spurious correlations), which can lead to misleading conclusions.\n",
        "\n",
        "### **What are confounders?**\n",
        "\n",
        "Correlation refers to a statistical relationship where two variables move together, but it does not imply that one causes the other. Causation, on the other hand, indicates that changes in one variable directly result in changes in another.\n",
        "\n",
        "**Confounders are variables that influence both the independent and dependent variables, creating a false impression of a relationship between them**. This can lead to the mistaken assumption of causation when, in fact, the confounder is the true underlying factor affecting both variables (see Figure 3).\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/spurrious_correlation.png?raw=true width=\"500\"><figcaption> Figure 1. An example of an easily recognizable spurious correlation.\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/caus_and_corr.png?raw=true width=\"300\"><figcaption> Figure 2. A comparison between correlation and causation.\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "You have already seen the example in *Figure 3* in the talk by Prof. Hesser but it is a very famous example of spurrious correlation as it was published in high-ranking medical journal.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/chocolate_nobel-laureates.png?raw=true width=\"600\"><figcaption> Figure 3. Spurrious correlation of chocolate consumption and nobel laureates (source: Messerli FH. Chocolate consumption, cognitive function, and Nobel laureates. N Engl J Med. 2012 doi: 10.1056/NEJMon1211064)\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "However, the issue with interpreting a causal relation from this graph is that the experiment does not account for the Gross Domestic Producs (GDP). If we account for the GDP, the apparent correlation vanishes. In the context of the graphs you can think of controlling for the GDP by binning the countries so that countries with similar GDP are grouped together. If you fix the GDP by only regarding one bin, the plot showoing chocolate consumption to numbers of nobel laureates wont depict a positive correlation anymore.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/causal-effect-chocolate-nobel.png?raw=true width=\"500\"><figcaption> Figure 4. Causal graph depicting the spurrious correlation of chocolate consumption and nobel laureates (source: Kondo et al. \"Causal-Effect Analysis using Bayesian LiNGAM Comparing with Correlation Analysis in Function Point Metrics and Effort. 10.33889/IJMEMS.2018.3.2-008.)\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "In this example, we can see in *Figure 5* graph D & E that the GDP positively correlates with nobel laureates and with chocolate consumption. One might actually argue a causal relationship as the GDP directly influences the education of the country as well as the purchase power of the citizens.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/gdp_to_nobels.png?raw=true width=\"1000\"><figcaption> Figure 5. Different graphs depicting number of laureates as a function of treatments (source: Maurage et al. \"Does chocolate consumption really boost Nobel Award chances? The peril of over-interpreting correlations in health studies.\" The Journal of nutrition, 143 6, 931-3 .)\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "**So we have seen, that a confounder, i.e. a variable which causes both the treatment and the outcome, can result in spurrious inference when dealing with oberservational data.**\n",
        "\n",
        "\n",
        "### **What is selection bias?**\n",
        "\n",
        "**So why don't we just controll for all variables we can get? Sadly, it is not so easy..**\n",
        "\n",
        "To show why, let's go back a step: We have learned that confounding occurs when the treatment and outcome share a common cause.\n",
        "For instance, if education is the treatment and income is the outcome, it is difficult to determine the true effect of education on income because they both share a common cause: intelligence. One could argue that higher earnings among more educated people may result from their intelligence, not just their education. To identify the causal effect, we need to block all backdoor paths between the treatment and outcome. By doing this, the only remaining effect is the direct one.\n",
        "\n",
        "In this example, if we control for intelligence—comparing people with the same intelligence but different levels of education—any difference in income will be due to education alone, since intelligence is held constant.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/confounding_example.png?raw=true width=\"300\"><figcaption> Figure 6. Example of the confounding variable \"Intelligence\" in the mentioned example (source: https://matheusfacure.github.io/python-causality-handbook/04-Graphical-Causal-Models.html)\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "While we can't directly measure intelligence, we can capture some of its causes, like the education levels of the father and mother, as well as some of its effects, such as IQ or SAT scores. Controlling for these surrogate variables doesn’t fully eliminate bias, but it does help reduce it.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/all_confounders_exmple.png?raw=true width=\"500\"><figcaption> Figure 7. Surrogates of \"Intelligence\" to account for the confounder (source: https://matheusfacure.github.io/python-causality-handbook/04-Graphical-Causal-Models.html)\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "\n",
        "Now the second major bias comes into play - selection bias. It's helpful to distinguish this from confounding bias. While confounding occurs when we fail to control for a common cause, selection bias is more about controlling for effects. Economists often use \"selection bias\" to describe various biases, so it's worth clarifying.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/selection_bias_problem.png?raw=true width=\"350\"><figcaption> Figure 8. source: https://matheusfacure.github.io/python-causality-handbook/04-Graphical-Causal-Models.html.\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "\n",
        "Selection bias often happens when we control for too many variables. For example, the treatment and outcome might be independent but become dependent when we condition on a collider.\n",
        "\n",
        "Imagine you could randomize education to measure its effect on wages. To avoid confounding, you control for several variables, including investments. However, investment isn’t a common cause of education and wages but rather a consequence of both—more educated people tend to earn and invest more. By controlling for investment (a collider), you unintentionally create a secondary link between education and wages, complicating the measurement of the direct effect. Essentially, you focus on groups with similar investments, limiting wage variation and preventing you from observing how education truly affects wages.\n",
        "In other words, among those who invest, the ones who manage to do so even without education are more likely to achieve high earnings, which as a consequence introduces bias. Conditioned on investing, higher education is associated with low wages and we have a negative bias.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/collider_example.png?raw=true width=\"300\"><figcaption> Figure 9. Example of a selection bias through a collider variable (source: https://matheusfacure.github.io/python-causality-handbook/04-Graphical-Causal-Models.html)\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "\n",
        "\n",
        "Similar thing happens when we condition on a mediator of the treatment. A mediator is a variable between the treatment and the outcome. For example, suppose again you can randomize education. But, just to be sure, you decide to control whether or not the person had a white-collar job. Once again, this conditioning biasses the causal effect estimation. This time, not because it opens a front door path with a collider (as it was the case with \"investments\"), but because it closes one of the channels through which the treatment operates. In this example, getting a white-collar job is one way how more education leads to higher pay. By controlling it, we close this channel and leave open only the direct effect of education on wages.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/mediator_selection_bias.png?raw=true width=\"350\"><figcaption> Figure 10. Example of a selection bias through a mediater variable (source: https://matheusfacure.github.io/python-causality-handbook/04-Graphical-Causal-Models.html)\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "In other words, among those who manage to get a white-collar job, the ones without education are probably more hard-working and are more likely to achieve high earnings than those who require the help of education to get the same job are, which as a consequence introduces again negative bias.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB7YK9-fMedB"
      },
      "source": [
        "# **Task 1:** Seeing the effect of the selection bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkMgToaWSTcW"
      },
      "source": [
        "**Now let's take a look at a medical example:**\n",
        "\n",
        "In this task, you will work through an example that simulates the relationship between various health factors—such as genetic predisposition, cholesterol levels, and risk of a heart attack. Specifically, you will explore **how controlling for a collider impacts the observed relationships between variables**.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/collider_task.png?raw=true width=\"300\"><figcaption>.\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "**Scenario**: We are simulating a medical setting where patients’ genetic predisposition influences their cholesterol levels, which in turn both affects their likelihood of taking cholesterol medication and the risk of a heart attack. Our goal is to investigate the bias introduced when we control for a collider (medication use)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WD9m-o1oLzS"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install statsmodels\n",
        "!pip install plotnine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drpb51QxHUNG"
      },
      "outputs": [],
      "source": [
        "#@title Task\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import plotnine as p\n",
        "from plotnine.themes import theme\n",
        "import warnings\n",
        "\n",
        "# Suppress plotnine warnings Koko\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data of 2500 random genetic predispositions\n",
        "n = 2500\n",
        "\n",
        "\"\"\"\n",
        "TASK 1:\n",
        "------\n",
        "Code the equations:\n",
        "Generate the \"Genetic Predisposition\" using n normally distributed variables.\n",
        "\n",
        "Define the \"High Cholesterol\" variable as a linear function of \"Genetic Predisposition\"\n",
        "with a random noise offset. The scaling factor for \"Genetic Predisposition\" should be equal to 1.5.\n",
        "\n",
        "Define the \"Risk of Heart Attack\" variable as a linear function of \"High Cholesterol\"\n",
        "with a random noise offset. The scaling factor should be 0.5.\n",
        "\n",
        "Define the \"Cholesterol Medication\" variable as a linear function of \"High Cholesterol\" and \"Risk of Heart Attack\"\n",
        "with a random noise offset. The scaling factors should be 0.4 and 0.6 respectively.\n",
        "Later we will binarize the \"Cholesterol Medication\" based on the 85% percentile to highlight the problem of collider controlling!\n",
        "\"\"\"\n",
        "\n",
        "# genetic_predisposition =                                                        # Independent variable\n",
        "# high_cholesterol =                                                              # Dependent variable - High Cholestoral\n",
        "# risk_of_heart_attack =                                                        # Outcome - Risk of Heart Attack (Y)\n",
        "# cholesterol_medication =                                                        # Collider  - Cholestorol Medication(M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkOUpcs6LOUu"
      },
      "outputs": [],
      "source": [
        "#@title Hint\n",
        "\n",
        "# Use np.random.normal(size) and set the argument \"size\" to generate random variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysfC5ecmMx0q"
      },
      "outputs": [],
      "source": [
        "#@title Solution\n",
        "\n",
        "# Of course the factors could are chosen empirically!\n",
        "\n",
        "genetic_predisposition = np.random.normal(size=n)  # Independent variable\n",
        "high_cholesterol = 1.5 * genetic_predisposition + np.random.normal(size=n)  # Dependent variable - High Cholestoral\n",
        "risk_of_heart_attack = 0.5 * high_cholesterol + np.random.normal(size=n)  # Outcome - Risk of Heart Attack (Y)\n",
        "cholesterol_medication = 0.4 * high_cholesterol + 0.6 * risk_of_heart_attack + np.random.normal(size=n)  # Collider  - Cholestorol Medication(M)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJGZTpE8xD0K"
      },
      "source": [
        "**Please execute the above task cell after solving the task.**\n",
        "\n",
        "**The next code cell you may just execute, you do not need to alter it but you are welcome to do so.**\n",
        "\n",
        "*What the following code cell does:*\n",
        "\n",
        "The code generates a Pandas Dataframe of the all included variables and defines a 'Medication' column which is binarized according to whether a patient’s score exceeds the 85th percentile.\n",
        "\n",
        "A function get_regression_params is defined to calculate the intercept, slope, and R² value for a linear regression model.\n",
        "\n",
        "Three plots are created using plotnine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiCuo_0swPjK"
      },
      "outputs": [],
      "source": [
        "#@title Rest of the Code\n",
        "\n",
        "# Create a DataFrame\n",
        "data_collider = pd.DataFrame({\n",
        "    'genetic_predisposition': genetic_predisposition,\n",
        "    'high_cholesterol': high_cholesterol,\n",
        "    'cholesterol_medication': cholesterol_medication,\n",
        "    'risk_of_heart_attack': risk_of_heart_attack\n",
        "})\n",
        "\n",
        "# Calculate the score (sum of high_cholesterol and risk of heart attack) and the 85th percentile\n",
        "data_collider['score'] = data_collider['high_cholesterol'] + data_collider['risk_of_heart_attack']\n",
        "percentile_85 = np.percentile(data_collider['score'], 85)\n",
        "\n",
        "# Create a binary variable 'medication' based on the 85th percentile.\n",
        "# We do this to reference that people who have cholesterol medication are likely to be both at CA risk and\n",
        "# have high cholesterol.\n",
        "data_collider['medication'] = (data_collider['score'] > percentile_85).astype(int)\n",
        "\n",
        "# Function to get regression parameters for each group, including intercept, slope, and R-squared\n",
        "def get_regression_params(data, formula):\n",
        "    model = smf.ols(formula=formula, data=data).fit()\n",
        "    intercept = model.params.iloc[0]  # Intercept\n",
        "    slope = model.params.iloc[1]      # Slope\n",
        "    r_squared = model.rsquared        # R-squared value\n",
        "    return intercept, slope, r_squared\n",
        "\n",
        "# Get regression parameters for the plots\n",
        "params_no_control = get_regression_params(data_collider, 'risk_of_heart_attack ~ high_cholesterol')\n",
        "params_med_control = get_regression_params(data_collider[data_collider['medication'] == 1], 'risk_of_heart_attack ~ high_cholesterol')\n",
        "params_no_med_control = get_regression_params(data_collider[data_collider['medication'] == 0], 'risk_of_heart_attack ~ high_cholesterol')\n",
        "\n",
        "# Plot: Risk of Heart Attack vs High Cholesterol (No control for medication)\n",
        "plot4 = (\n",
        "    p.ggplot(data_collider, p.aes(x='high_cholesterol', y='risk_of_heart_attack')) +\n",
        "    p.geom_point(size=0.5) +\n",
        "    p.geom_smooth(method='lm', color='blue') +\n",
        "    p.labs(title='Risk of CA vs High Cholesterol (No Control)', x='High Cholesterol', y='Risk of Heart Attack') +\n",
        "    p.xlim(-4, 4) +\n",
        "    p.ylim(-4, 4) +\n",
        "    p.geom_label(\n",
        "        x=-3, y=3.5,\n",
        "        label=f'Intercept: {params_no_control[0]:.2f}\\nSlope: {params_no_control[1]:.2f}\\nR²: {params_no_control[2]:.2f}',\n",
        "        size=8, color='black', fill='orange'\n",
        "    ) +\n",
        "    p.theme(plot_title=p.element_text(ha='center'))  # Center the plot title\n",
        ")\n",
        "\n",
        "# Plot: Controlling for medication (Collider)\n",
        "plot5 = (\n",
        "    p.ggplot(data_collider[data_collider['medication'] == 1], p.aes(x='high_cholesterol', y='risk_of_heart_attack')) +\n",
        "    p.geom_point(size=0.5) +\n",
        "    p.geom_smooth(method='lm', color='red') +\n",
        "    p.labs(title='Risk of CA vs High Cholesterol (Medication Group)', x='High Cholesterol', y='Risk of Heart Attack') +\n",
        "    p.xlim(-4, 4) +\n",
        "    p.ylim(-4, 4) +\n",
        "    p.geom_label(\n",
        "        x=-3, y=3.5,\n",
        "        label=f'Intercept: {params_med_control[0]:.2f}\\nSlope: {params_med_control[1]:.2f}\\nR²: {params_med_control[2]:.2f}',\n",
        "        size=8, color='black', fill='orange'\n",
        "    ) +\n",
        "    p.theme(plot_title=p.element_text(ha='center'))  # Center the plot title\n",
        ")\n",
        "\n",
        "# Plot: No Medication Group\n",
        "plot6 = (\n",
        "    p.ggplot(data_collider[data_collider['medication'] == 0], p.aes(x='high_cholesterol', y='risk_of_heart_attack')) +\n",
        "    p.geom_point(size=0.5) +\n",
        "    p.geom_smooth(method='lm', color='green') +\n",
        "    p.labs(title='Risk of CA vs High Cholesterol (No-Medication Group)', x='High Cholesterol', y='Risk of Heart_Attack') +\n",
        "    p.xlim(-4, 4) +\n",
        "    p.ylim(-4, 4) +\n",
        "    p.geom_label(\n",
        "        x=-3, y=3.5,\n",
        "        label=f'Intercept: {params_no_med_control[0]:.2f}\\nSlope: {params_no_med_control[1]:.2f}\\nR²: {params_no_med_control[2]:.2f}',\n",
        "        size=8, color='black', fill='orange'\n",
        "    ) +\n",
        "    p.theme(plot_title=p.element_text(ha='center'))  # Center the plot title\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lrWPlbnYuOm"
      },
      "outputs": [],
      "source": [
        "# Display the plots\n",
        "plot4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9blsC4GdYw8f"
      },
      "outputs": [],
      "source": [
        "# Display the plots\n",
        "plot5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaRMhzQTY06Y"
      },
      "outputs": [],
      "source": [
        "# Display the plots\n",
        "plot6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKB-hh5Wmh3-"
      },
      "source": [
        "## Questions\n",
        "\n",
        "**What can you observe?**\n",
        "\n",
        "**Can you think of an example of a mediator influencing the outcome which itself influenced by the exposure (genetic predisposition)**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WuGRYiUjMtS"
      },
      "source": [
        "# Fundamentals and Mathematics of Treatment Effect Estimation\n",
        "\n",
        "\n",
        "### This is just theoretical background for the interested reader!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tlzhbOisEHD"
      },
      "source": [
        "Causal treatment effect estimation is the process of quantifying the impact of a specific intervention or treatment on an outcome of interest, while accounting for confounding factors. It aims to measure the difference in outcomes between a treated group and a control group, ensuring that this difference is due to the treatment itself rather than other external variables. In observational studies, where random assignment is not possible, methods such as propensity score matching, instrumental variables, or regression analysis are used to control for confounders.\n",
        "\n",
        "The fundamental goal is to isolate the causal effect, ensuring that the observed relationship is not spurious or driven by other influences. For example, in medicine, causal treatment effect estimation can help determine whether a new drug improves patient recovery, independent of factors like age, health history, or other treatments. By accurately estimating treatment effects, researchers can make more informed decisions, allowing policymakers or practitioners to adopt interventions that have a true, positive impact on outcomes. The challenge lies in distinguishing correlation from causation, especially in non-experimental data, where confounding biases are harder to control.\n",
        "\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/chd.png?raw=true width=\"800\"><figcaption> Figure 11. Overview over Causal Inference Causal Inference\n",
        "</a></figcaption></figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYsz21ZwsuCh"
      },
      "source": [
        "## Potential Outcomes Framework\n",
        "\n",
        "The **potential outcomes framework** defines causal effects using hypothetical outcomes under different treatment conditions. Core concepts include the **average treatment effect (ATE)**, **conditional average treatment effect (CATE)**, and **individual treatment effect (ITE)**, as well as the **do operator** from causal inference.\n",
        "\n",
        "#### 1. **Potential Outcomes**\n",
        "\n",
        "For each unit $i$, define two potential outcomes:\n",
        "- $Y_i(1)$: outcome if patient $i$ receives treatment,\n",
        "- $Y_i(0)$: outcome if patient $i$ does not receive treatment.\n",
        "\n",
        "Only one outcome is observed for each unit based on the treatment assignment $ T_i $. The observed outcome is:\n",
        "\n",
        "$$\n",
        "Y_i^{obs} = T_i Y_i(1) + (1 - T_i) Y_i(0)\n",
        "$$\n",
        "\n",
        "#### 2. **Individual Treatment Effect (ITE)**\n",
        "\n",
        "The **ITE** measures the treatment effect for a specific individual:\n",
        "\n",
        "$$\n",
        "\\text{ITE}_i = Y_i(1) - Y_i(0)\n",
        "$$\n",
        "\n",
        "However, this is unobservable since both $Y_i(1)$ and $Y_i(0)$ cannot be observed for the same individual.\n",
        "\n",
        "#### 3. **Average Treatment Effect (ATE)**\n",
        "\n",
        "The **ATE** captures the average causal effect of the treatment across the population:\n",
        "\n",
        "$$\n",
        "\\text{ATE} = \\mathbb{E}[Y(1) - Y(0)] = \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)]\n",
        "$$\n",
        "\n",
        "It represents the expected difference in outcomes between treated and untreated populations.\n",
        "\n",
        "#### 4. **Conditional Average Treatment Effect (CATE)**\n",
        "\n",
        "The **CATE** measures the treatment effect for subgroups defined by covariates $X$:\n",
        "\n",
        "$$\n",
        "\\text{CATE}(X) = \\mathbb{E}[Y(1) - Y(0) \\mid X = x]\n",
        "$$\n",
        "\n",
        "This highlights heterogeneous effects based on specific characteristics.\n",
        "\n",
        "#### 5. **Do Operator and Causal Inference**\n",
        "\n",
        "The **do operator**, denoted $ \\text{do}(T = t) $, represents an intervention where a variable $ T $ is externally set to a particular value $ t $, breaking any natural causal relationships between $ T $ and other variables.\n",
        "\n",
        "The **interventional distribution** $ P(Y \\mid \\text{do}(T = t)) $ is defined by:\n",
        "\n",
        "$$\n",
        "P(Y \\mid \\text{do}(T = t)) = \\sum_{x} P(Y \\mid T = t, X = x) P(X = x)\n",
        "$$\n",
        "\n",
        "Here, $ Y $ is the outcome, $ T $ is the treatment, and $ X $ represents confounders or covariates. This equation represents the probability of $ Y $ given that $ T $ is set to $ t $ through intervention, while accounting for the distribution of $ X $.\n",
        "\n",
        "The distribution $ P(Y \\mid \\text{do}(T = t)) $ is **not** the same as $ P(Y \\mid T = t) $. The do operator $ \\text{do}(T = t) $ forces $ T $ to be set to $ t $ as an intervention, whereas $ P(Y \\mid T = t) $ simply conditions on $ T = t $ without considering causal intervention.\n",
        "\n",
        "### The average treatment effect (ATE)\n",
        "\n",
        "Using the do-Operator the **ATE** is given now by:\n",
        "\n",
        "$$\n",
        "\\text{ATE} = \\mathbb{E}[Y \\mid \\text{do}(T = 1)] - \\mathbb{E}[Y \\mid \\text{do}(T = 0)]\n",
        "$$\n",
        "\n",
        "In observational studies, causal effects are estimated using techniques like **propensity scores** or **instrumental variables** to approximate this idealized intervention.\n",
        "\n",
        "The big problem with estimating However, we can never observe both **Y(1)** and **Y(0)** for the same individual, which is known as the **fundamental problem of causal inference**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJG0ACU8somM"
      },
      "source": [
        "## Assumtions for Causal Treatment Effect Estimation\n",
        "For valid estimation of the treatment effect, several key assumptions are typically required, particularly when using observational data. A few key assumptions were already highlighted above:\n",
        "\n",
        "\n",
        "1. **Stable Unit Treatment Value Assumption (SUTVA)**\n",
        "\n",
        "*   **Definition**: The potential outcomes for any individual should not be affected by the treatment assignment of other individuals (no interference), and the treatment is the same for all individuals (no hidden versions of the treatment).\n",
        "*   **Implication**: Each individual’s outcome is only determined by their own treatment assignment and not by others, ensuring that the treatment effect can be consistently defined.\n",
        "\n",
        "2. **Ignorability/Unconfoundedness**\n",
        "\n",
        "*  **Definition**: The treatment assignment is independent of the potential outcomes given the observed covariates: $$Y(0), Y(1) \\perp T \\mid X$$\n",
        "*  **Implication**: There are no unmeasured confounders, and treatment assignment is as good as random once we condition on the observed covariates.\n",
        "\n",
        "3. **Positivity/Overlap (Common Support)**\n",
        "\n",
        "*  **Definition**: For every value of the covariates XX, there is a positive probability of receiving each treatment (i.e., treated and untreated groups are sufficiently comparable). $$0 < P(T = 1 \\mid X) < 1 \\,\\, \\text{for all}\\,\\, X$$\n",
        "*  **Implication**: Every individual in the population has a non-zero probability of receiving either treatment or control, ensuring there is enough variation to make comparisons across treatment groups.\n",
        "\n",
        "4. **Consistency**\n",
        "\n",
        "* **Definition**: The observed outcome for an individual under a particular treatment is the same as the potential outcome for that individual under that treatment.\n",
        "* **Implication**: The treatment as defined in the study must correspond to the treatment that the individuals actually receive. There should be no ambiguity in treatment assignment or measurement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7TnKN-fj5y4"
      },
      "source": [
        "## Randomized Controlled Trials (RCTs)\n",
        "In RCTs, treatment assignment is randomized, which helps to estimate the causal effect without bias. When done correctly, it means nothing except for the treatment influences an outcomes. In this case causal effect can be easily estimated as a difference between outcomes of the treated and untreated groups. The figure below demonstrates graph of the ideal RCT. Note that only the treatment $T$ influences the outcome $Y$. Covariates $X$ are omitted as they assumed to be same for both treated and untreated subjects due to randomization.\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/rct.png?raw=true width=\"200\"><figcaption> Figure 12. Model of the RCT\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "One of the advantages of the RCTs is that in the simplest case an average treatment effect (ATE) can easily be found as $ATE=E[ITE(X)]=E[Y(1)−Y(0)] = E[Y(1)] - E[Y(0)]$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u8YRDNJgz1s"
      },
      "source": [
        "## Observational Data\n",
        "\n",
        " That is why data from *observational studies* is used for causal effect estimation.\n",
        "\n",
        "Observational data refers to data collected without any intervention or manipulation by the researcher. Observational studies rely on naturally occurring variations in treatment assignments.\n",
        "\n",
        "**Examples**:\n",
        "\n",
        "1.   Medical records where patients choose their treatments.\n",
        "2.   Economic data where policy changes affect different regions differently.\n",
        "3.   Social science surveys where participants report their behaviors and outcomes.\n",
        "\n",
        "The left image of the Fig. 2 demonstrates data generation process for the observational studies, where $X$ is an input vector of confounders. Confoudners are variables influencing both the treatment $T$ and the outcome $Y$. Without considering them, the outcome $Y$ will be biased. On the right side we can see the situation after intervention on the $T$. Intervention means setting $T=0$, or $T=1$ for all subjects in the dataset. It means for an ITE estimation we should know all the variables influencing $Y$.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/causal_graphs.png?raw=true width=\"500\"><figcaption> Figure 13. Left: Model of data generation in the observational studies. Right: Model after intervention.</a></figcaption></figure></center>\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/intervention.png?raw=true width=\"400\"><figcaption> Figure 14. Causal model and Intervention\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "In order to estimate ITE from observational studies one has to take all the variables inluencing treatment assignment and outcome into consideration.\n",
        "The ITE, which can be viewed as the Conditional Average Treatment Efffect (CATE) when conditioned on the exact set of variables of one individual $x_i$, from the observational studies can be computed as $$ \\tau(x_i) = \\mathbb{E}[Y^1 - Y^0|X = x_i].$$ It means one has to estimate $\\mathbb{E}[{Y^1}|x_i]$ and $\\mathbb{E}[{Y^0}|x_i]$  using machine learning techniques.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kReg1J6P1Neb"
      },
      "source": [
        "# **Task 2:** ATE Estimation in case of a simulated RCT and Observational Studies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MabAd2tK05AU"
      },
      "source": [
        "Below is an example of ATE estimation on a simple artificial RCT dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRt8HMWvjQjN"
      },
      "outputs": [],
      "source": [
        "# Simulating a simple RCT to estimate ATE\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "X = np.random.normal(0, 1, (n, 2))  # Covariates X\n",
        "T = np.random.binomial(1, 0.5, n)  # Random treatment assignment T\n",
        "true_ate= 2.0  # True treatment effect\n",
        "Y = X[:, 0] + true_ate * T + np.random.normal(0, 1, n)  # Outcome\n",
        "\n",
        "data = pd.DataFrame({'X1': X[:, 0], 'X2': X[:, 1], 'Treatment': T, 'Outcome': Y})\n",
        "\n",
        "# Calculate ATE\n",
        "ate = data[data['Treatment'] == 1]['Outcome'].mean() - data[data['Treatment'] == 0]['Outcome'].mean()\n",
        "print(f\"Estimated ATE: {ate:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLayX7HVrJje"
      },
      "source": [
        "**Task**\n",
        "\n",
        "In observational studies treatment assignment can be biased. To explore what\n",
        "happens in this case update the example above. Instead of assigning treatment at random set $T=1$ for subjects with `X[:, 0] > 0.1`.\n",
        "\n",
        "Can you see the difference in the ATE compared to the original example?\n",
        "To estimate the treatment effect we can use a linear regression. What would be the estimated ATE?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMOiS7hJiq0x"
      },
      "outputs": [],
      "source": [
        "# Simulate data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "X = np.random.normal(0, 1, (n, 2))  # Covariates X\n",
        "T = np.zeros(n) # Random treatment assignment T\n",
        "# write the code here\n",
        "T...\n",
        "\n",
        "true_ate= 2.0  # True treatment effect\n",
        "\n",
        "Y = X[:, 0] + true_ate * T + np.random.normal(0, 1, n)  # Outcome\n",
        "\n",
        "data = pd.DataFrame({'X1': X[:, 0], 'X2': X[:, 1], 'Treatment': T, 'Outcome': Y})\n",
        "\n",
        "# Calculate ATE\n",
        "ate = data[data['Treatment'] == 1]['Outcome'].mean() - data[data['Treatment'] == 0]['Outcome'].mean()\n",
        "print(f\"Estimated ATE: {ate:.2f}\")\n",
        "\n",
        "# Use linear regression\n",
        "# Create DataFrame\n",
        "data = pd.DataFrame({'X1': X[:, 0], 'X2': X[:, 1], 'Treatment': T, 'Outcome': Y})\n",
        "\n",
        "# Prepare X matrix for regression (including the treatment and covariates)\n",
        "X_data = sm.add_constant(data[['X1', 'X2', 'Treatment']])\n",
        "\n",
        "# Fit linear regression model\n",
        "model = sm.OLS(data['Outcome'], X_data).fit()\n",
        "\n",
        "# Print regression summary\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeSSkPKw4dQf"
      },
      "outputs": [],
      "source": [
        "# @title Solution { display-mode: \"form\" }\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "X = np.random.normal(0, 1, (n, 2))  # Covariates X\n",
        "T = np.zeros(n) # Random treatment assignment T\n",
        "T[X[:, 0] > 0.1] = 1\n",
        "\n",
        "true_ate= 2.0  # True treatment effect\n",
        "\n",
        "Y = X[:, 0] + true_ate * T + np.random.normal(0, 1, n)  # Outcome\n",
        "\n",
        "data = pd.DataFrame({'X1': X[:, 0], 'X2': X[:, 1], 'Treatment': T, 'Outcome': Y})\n",
        "\n",
        "# Calculate ATE\n",
        "ate = data[data['Treatment'] == 1]['Outcome'].mean() - data[data['Treatment'] == 0]['Outcome'].mean()\n",
        "print(f\"Estimated ATE: {ate:.2f}\")\n",
        "\n",
        "# Use linear regression\n",
        "# Create DataFrame\n",
        "data = pd.DataFrame({'X1': X[:, 0], 'X2': X[:, 1], 'Treatment': T, 'Outcome': Y})\n",
        "\n",
        "# Prepare X matrix for regression (including the treatment and covariates)\n",
        "X_data = sm.add_constant(data[['X1', 'X2', 'Treatment']])\n",
        "\n",
        "# Fit linear regression model\n",
        "model = sm.OLS(data['Outcome'], X_data).fit()\n",
        "\n",
        "# Print regression summary\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl2gDLjBYHRF"
      },
      "source": [
        "# Notation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4Kzl7oGkJU"
      },
      "source": [
        "**Causal identification**\n",
        "\n",
        "- Observed covariates/features: $X$\n",
        "\n",
        "- Potential outcomes: $Y^0$ and $Y^1$\n",
        "\n",
        "- Treatment: $T$\n",
        "\n",
        "- Average Treatment Effect: $ATE =\\mathbb{E}[Y^1-Y^0]$\n",
        "\n",
        "- Conditional Average Treatment Effect: $CATE =\\mathbb{E}[Y^1-Y^0|X=x]$\n",
        "\n",
        "**Deep learning estimation**\n",
        "\n",
        "- Predicted outcomes: $\\hat{Y}^0$ and $\\hat{Y}^1$\n",
        "\n",
        "- Outcome modeling functions: $\\hat{Y}(T)=h(X,T)$\n",
        "\n",
        "- Representation functions: $\\Phi(X)$ (producing representations $\\phi$)\n",
        "\n",
        "- Loss functions: $\\mathcal{L}(true,predicted)$, with the mean squared error abbreviated $MSE$ and binary cross-entropy as $BCE$\n",
        "\n",
        "- Estimated CATE: $\\hat{CATE}=(1-2t)(\\hat{{y}}(t)-\\hat{y}(1-t))$\n",
        "\n",
        "- Estimated ATE: $\\hat{ATE}=\\frac{1}{n}\\sum_{i=1}^n\\hat{CATE_i}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plnw_9HlY2t5"
      },
      "source": [
        "# The ITE models trained in this workshop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdnneVO4Y01N"
      },
      "source": [
        "To find the treatment effect one has to use more advanced causal inference methods based, for example, on neural networks. These include meta-learners S-Learner and T-Learner, representation based methods such as TARnet, GNN-TARnet, and CFR-Wass. We give a quick introduction to the methods below.\n",
        "\n",
        "### S-Learner\n",
        "The S-Learner is using several fully-connected layers to make predictions. Input to the S-Linear coinsides with the input to linear regression model and consists of concatenated vectors $X$ and $T$. Mean Squared Error (MSE) is used as a loss function $MSE = ∑(\\bar{\\mu}_i - y_i)$. The S-Learner has a a high bias towards the covariates as the treatment is granted no extra handling - it is simply concatenated to the input vector $x$ and hence the treatment shows little effect on the outcome.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/s-learner.png?raw=true width=\"700\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "\n",
        "### T-Learner\n",
        "The T-Learner uses separate networks to predict outcomes for each of the treatments individually. Unlike S-Learner the treatment is no longer concatenated with the covariates which makes destinction between treatments easier. It has a MSE loss function separate for each treatment case.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/t-learner.png?raw=true width=\"600\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "\n",
        "### TARnet\n",
        "The TARnet (Treatment Agnostic Regression net) is a combination of S-Learner and T-Learner trying to get the best of both worlds. First the covariates $X$ are passed through fully-connected layers which tries to learn a joint representation of both groups. This representation is then passed through treatment specific branches which are seperately updated based on the actual value of the treatment variable per input patient. However the TARnet is forced to predict both potential outcomes for each input.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/tarnet.png?raw=true width=\"700\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "\n",
        "### CFRnet\n",
        "\n",
        "The CFRnet (Counterfactual Regression Network) is very similar to the TARnet. The difference here is that it focuses on learning counterfactual outcomes by minimizing the discrepancy between treated and control groups through an integral probability metric (IPM), aiming to predict individual treatment effects (ITE). In this way it helps the learn the joint representation by inforcing the representational distributions of the groups to be similar.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/cfrnet.png?raw=true width=\"800\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kvhRLd1JyAp"
      },
      "source": [
        "# The Data used for this Workshop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WBrCYRj_Z3c"
      },
      "source": [
        "First of of all let's load the IHDP dataset.\n",
        "\n",
        "<center><figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/icons_ihdp.png?raw=true width=\"300\"><figcaption> Figure 15. The IHDP dataset consists of infants receiving different treatments regaridng a development program.\n",
        "</a></figcaption></figure></center>\n",
        "\n",
        "The Infant Health and Development Program was a collaborative, randomized, longitudinal, multisite clinical trial designed to evaluate the efficacy of comprehensive early intervention in reducing the developmental and health problems of low birth weight, premature infants. An intensive intervention extending from hospital discharge to 36 months corrected age was administered between 1985 and 1988 at eight different sites. The study sample of infants was stratified by birth weight (2,000 grams or less, 2,001-2,500 grams) and randomized to the Intervention Group or the Follow-Up Group. The Intervention Group received home visits, attendance at a special child development center, and pediatric follow-up. The Follow-Up Group received only the pediatric follow-up component of the program. Measures of cognitive development, behavioral status, health status, and other variables were collected from both groups at predetermined time points. Cognitive development was assessed by the Stanford-Binet Intelligence Scale, the Bayley Mental and Motor Scales, the Peabody Picture Vocabulary Test--Revised, and the Beery-Buktenica Developmental Test of Visual Motor Integration. Behavior problems were measured using the Richman-Graham Behavior Checklist and Achenbach's Child Behavior Checklist. Health status was evaluated through the dimensions of morbidity (defined as the presence or absence of health conditions), functional status (defined by limitations in activities of daily living due to health problems), changes in physical growth, and maternal perception of the child's health. The many other variables and indices in the data collection include site, pregnancy complications, child's birth weight and gestation age, birth order, child's gender, household composition, day care arrangements, source of health care, quality of the home environment, parents' race and ethnicity, and maternal age, education, IQ, and employment.\n",
        "\n",
        "\n",
        "The IHDP dataset is a naturalistic simulation introduced in [Hill, 2011](https://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162?casa_token=b8-rfzagECIAAAAA:QeP7C4lKN6nZ7MkDjJHFrEberXopD9M5qPBMeBqbk84mI_8qGxj01ctgt4jdZtORpu9aZvpVRe07PA) to evaluate estimation of heterogeneous treatment effects ($CATE$). The  25 covariates/features for the 747 units (139 treated) in the dataset were taken from an experiment, but Hill simulated the outcomes to create known counterfactuals. IHDP is the benchmark in the literature.\n",
        "\n",
        "<details><summary>Additional details from Hill, 2011</summary>\n",
        "<blockquote>[Hill] used experimental data from the Infant Health and Development Program (IHDP), a randomized experiment that began in 1985, targeted low-birth-weight, premature infants, and provided the treatment group with both intensive high-quality child care and home visits from a trained provider.... [The response surface] is nonlinear and not parallel across treatment conditions, with $Y(0)∼\\mathcal{N}(exp((X+W)\\beta_B),1)$ and $Y(1)∼\\mathcal{N}(X\\beta_B−\\omega^s_B,1)$, where $W$ is an offset matrix of the same dimension as $X$ with every value equal to 0.5, $\\beta_B$ is a vector of regression coefficients (0, 0.1, 0.2, 0.3, 0.4) randomly sampled with probabilities (0.6, 0.1, 0.1, 0.1,0.1). For the sth simulation, $\\omega^s_B$ was chosen in the overlap setting, where we estimate the effect of the treatment on the treated, such that theconditional average treatment effect for the treated equals 4.</blockquote>\n",
        "</details>\n",
        "\n",
        "`y` is the simulated outcome that may represent $Y^0$ or $Y^1$ depending on `t`. Note that we rescale it here to improve convergence. `mu_0` and `mu_1` are \"noiseless\" potential outcomes where Hill simply used the mean of the normal distribution described in the spoiler.\n",
        "\n",
        "There are 100 stochastic simulations in this data. For this example we will just use only five first. ([Source](https://osf.io/preprints/socarxiv/aeszf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az99QzOWbqUy"
      },
      "source": [
        "# **Task 3:** Individual Treatment Effect Estimation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the treatment effect one has to use more advanced causal inference methods based, for example, on neural networks. These include meta-learners S-Learner and T-Learner, representation based methods such as TARnet, GNN-TARnet, and CFR-Wass. We give a quick introduction to the methods below.\n",
        "\n",
        "### S-Learner\n",
        "The S-Learner is using several fully-connected layers to make predictions. Input to the S-Linear coinsides with the input to linear regression model and consists of concatenated vectors $X$ and $T$. Mean Squared Error (MSE) is used as a loss function $MSE = ∑(\\bar{\\mu}_i - y_i)$. The S-Learner has a a high bias towards the covariates as the treatment is granted no extra handling - it is simply concatenated to the input vector $x$ and hence the treatment shows little effect on the outcome.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/s-learner.png?raw=true width=\"700\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "\n",
        "### T-Learner\n",
        "The T-Learner uses separate networks to predict outcomes for each of the treatments individually. Unlike S-Learner the treatment is no longer concatenated with the covariates which makes destinction between treatments easier. It has a MSE loss function separate for each treatment case.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/t-learner.png?raw=true width=\"600\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "\n",
        "### TARnet\n",
        "The TARnet (Treatment Agnostic Regression net) is a combination of S-Learner and T-Learner trying to get the best of both worlds. First the covariates $X$ are passed through fully-connected layers which tries to learn a joint representation of both groups. This representation is then passed through treatment specific branches which are seperately updated based on the actual value of the treatment variable per input patient. However the TARnet is forced to predict both potential outcomes for each input.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/tarnet.png?raw=true width=\"700\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "\n",
        "### CFRnet\n",
        "\n",
        "The CFRnet (Counterfactual Regression Network) is very similar to the TARnet. The difference here is that it focuses on learning counterfactual outcomes by minimizing the discrepancy between treated and control groups through an integral probability metric (IPM), aiming to predict individual treatment effects (ITE). In this way it helps the learn the joint representation by inforcing the representational distributions of the groups to be similar.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/cfrnet.png?raw=true width=\"800\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>\n",
        "\n",
        "### GGNTarnet\n",
        "\n",
        "The GNNTarnet is the modification of TARnet using GNN layers instead of the FC layers.\n",
        "\n",
        "<center>\n",
        "<figure><img src=https://github.com/dyh1265/Causal-Inference-Library/blob/master/images/gnntarnet.PNG?raw=true width=\"800\"><figcaption>\n",
        "</a></figcaption></figure>\n",
        "</center>"
      ],
      "metadata": {
        "id": "6KyXDs1_iSpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries. Restart session after finishing installation if promted."
      ],
      "metadata": {
        "id": "zy8OjhYeMeqJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSgZ8pPzhQWE"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner\n",
        "!pip install lingam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orMh0EZGKUs1"
      },
      "source": [
        "Clone the repository"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "# remove local directory if it already exists\n",
        "repo = \"Causal-Inference-Library\"\n",
        "if os.path.isdir(repo):\n",
        "    !rm -rf {repo}\n",
        "    # keep the latest version\n",
        "!git clone --depth=1 https://github.com/dyh1265/Causal-Inference-Library.git\n",
        "os.chdir('Causal-Inference-Library')"
      ],
      "metadata": {
        "id": "GSljwyyyCnqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4qi3FhLDhMf"
      },
      "source": [
        "Here is the function to load IHDP dataset. We use StandardScaler to scale the outcomes for better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJdXqH8oDn_3"
      },
      "outputs": [],
      "source": [
        "#\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "def load_ihdp_data(path_data, i=7):\n",
        "        \"\"\"\n",
        "         Load IHDP data for a specified fold number.\n",
        "\n",
        "         Args:\n",
        "             path_data (str): Path to the directory where the IHDP data is stored.\n",
        "             i (int): Fold number to load (default is 7).\n",
        "\n",
        "         Returns:\n",
        "             tuple: A tuple of two dictionaries representing the training and testing data.\n",
        "                 Each dictionary contains the following keys:\n",
        "                 - 'x': A numpy array representing the covariates.\n",
        "                 - 't': A numpy array representing the treatment.\n",
        "                 - 'y': A numpy array representing the outcome.\n",
        "                 - 'mu_0': A numpy array representing the potential outcome under control condition.\n",
        "                 - 'mu_1': A numpy array representing the potential outcome under treatment condition.\n",
        "                 Additionally, the training data dictionary contains:\n",
        "                 - 'y_scaler': A sklearn StandardScaler object fitted on the training data 'y' values.\n",
        "                 - 'ys': A numpy array representing the rescaled 'y' values using the 'y_scaler' fitted on the training data.\n",
        "         \"\"\"\n",
        "\n",
        "        data_train = np.loadtxt(path_data + '/ihdp_npci_train_' + str(i + 1) + '.csv', delimiter=',', skiprows=1)\n",
        "        data_test = np.loadtxt(path_data + '/ihdp_npci_test_' + str(i + 1) + '.csv', delimiter=',', skiprows=1)\n",
        "\n",
        "        t_train, y_train = data_train[:, 0], data_train[:, 1][:, np.newaxis]\n",
        "        mu_0_train, mu_1_train, x_train = data_train[:, 3][:, np.newaxis], data_train[:, 4][:, np.newaxis], data_train[\n",
        "                                                                                                            :, 5:]\n",
        "\n",
        "        t_test, y_test = data_test[:, 0].astype('float32'), data_test[:, 1][:, np.newaxis].astype('float32')\n",
        "        mu_0_test, mu_1_test, x_test = data_test[:, 3][:, np.newaxis].astype('float32'), data_test[:, 4][:,\n",
        "                                                                                         np.newaxis].astype('float32'), \\\n",
        "            data_test[:, 5:].astype('float32')\n",
        "        data_train = {'x': x_train, 't': t_train, 'y': y_train, 'mu_0': mu_0_train, 'mu_1': mu_1_train}\n",
        "\n",
        "        data_train['t'] = data_train['t'].reshape(-1,\n",
        "                                                  1)  # we're just padding one dimensional vectors with an additional dimension\n",
        "        data_train['y'] = data_train['y'].reshape(-1, 1)\n",
        "        # rescaling y between 0 and 1 often makes training of DL regressors easier\n",
        "        data_train['y_scaler'] = StandardScaler().fit(data_train['y'])\n",
        "        data_train['ys'] = data_train['y_scaler'].transform(data_train['y'])\n",
        "\n",
        "        data_test = {'x': x_test, 't': t_test, 'y': y_test, 'mu_0': mu_0_test, 'mu_1': mu_1_test}\n",
        "        data_test['t'] = data_test['t'].reshape(-1,\n",
        "                                                1)  # we're just padding one dimensional vectors with an additional dimension\n",
        "        data_test['y'] = data_test['y'].reshape(-1, 1)\n",
        "        # rescaling y between 0 and 1 often makes training of DL regressors easier\n",
        "        data_test['y_scaler'] = data_train['y_scaler']\n",
        "        data_test['ys'] = data_test['y_scaler'].transform(data_test['y'])\n",
        "\n",
        "        return data_train, data_test\n",
        "\n",
        "def load_data(count):\n",
        "    \"\"\"\n",
        "      Loads the specified dataset.\n",
        "\n",
        "      Parameters:\n",
        "      ----------\n",
        "      dataset_name: str\n",
        "          The name of the dataset to load. Valid options include 'ihdp_a', 'ihdp_b', 'acic', 'twins', 'jobs', 'gnn', 'ihdp_g', and 'sum'.\n",
        "      count: int, optional\n",
        "          The number of the subset to load\n",
        "      Returns:\n",
        "      ----------\n",
        "      data: numpy.ndarray\n",
        "          The loaded dataset.\n",
        "\n",
        "      Raises:\n",
        "      ----------\n",
        "      ValueError: If an invalid dataset name is specified.\n",
        "\n",
        "      \"\"\"\n",
        "    path_data = \"./IHDP_a\"\n",
        "    return load_ihdp_data(path_data, count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9M_MayCERtT"
      },
      "source": [
        "Let's create the S-learner, one of the easiest methods for ITE estimation. It consists of several fully connected layers (FC). The code for creating FC layers is presented below. This is the building block for more complicated models.\n",
        "Here is the description of the parameters for the FullyConnected class:\n",
        "\n",
        "* `n_fc`: The number of fully connected layers.\n",
        "* `hidden_phi`: The number of neurons in the hidden layers.\n",
        "* `out_size`: The number of neurons in the output layer.\n",
        "* `final_activation`: The activation function for the output layer.\n",
        "* `name`: The name of the layer.\n",
        "* `kernel_reg`: The kernel regularizer.\n",
        "* `kernel_init`: The kernel initializer.\n",
        "* `activation`: The activation function for the hidden layers. Default is 'elu'.\n",
        "* `bias_initializer`: The bias initializer. Default is None.\n",
        "* `use_bias`: Whether to use bias. Default is True.\n",
        "`**kwargs`: Additional keyword arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcnvlT-YEqGj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Layer, Dense, BatchNormalization, Dropout\n",
        "\n",
        "class FullyConnected(Layer):\n",
        "    def __init__(self, n_fc, hidden_phi, out_size,  final_activation, name, kernel_reg, kernel_init, activation='elu',\n",
        "                 bias_initializer=None, use_bias=True, **kwargs):\n",
        "        super(FullyConnected, self).__init__(name=name, **kwargs)\n",
        "        self.Layers = []\n",
        "        for i in range(n_fc-1):\n",
        "            self.Layers.append(Dense(units=hidden_phi, activation=activation, kernel_initializer=kernel_init,\n",
        "                                     bias_initializer=bias_initializer, use_bias=use_bias,\n",
        "                                     kernel_regularizer=kernel_reg, name=name + str(i)))\n",
        "        self.Layers.append(Dense(units=out_size, activation=final_activation, name=name + 'out'))\n",
        "\n",
        "    def call(self, x):\n",
        "        for layer in self.Layers:\n",
        "            x = layer(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vA5MI21Kq_r"
      },
      "source": [
        "\n",
        "Make the computation deterministic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgISR7c1KvjX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def setSeed(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFdpktRzF-i1"
      },
      "source": [
        "Below is how to create the S-Learner model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmP4et-EKO-l"
      },
      "source": [
        "# Training the *S-Learner* for Causal Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoAvqxHwGb9F"
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "class SModel(Model):\n",
        "    def __init__(self, name='slearner', **kwargs):\n",
        "        super(SModel, self).__init__(name=name, **kwargs)\n",
        "        self.n_fc = 3\n",
        "        self.hidden_phi = 100\n",
        "        self.fc = FullyConnected(n_fc=self.n_fc, hidden_phi=self.hidden_phi,\n",
        "                                 final_activation='elu', out_size=1,\n",
        "                                 kernel_init='RandomNormal', kernel_reg=None, name='fc')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.fc(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EodF3_AXKQfp"
      },
      "source": [
        "Let's initialize and train it on IHDP_a dataset. In this case we are using Adam optimizer. Let us set the learning rate to be 1e-3. We are using a simple MSE loss. As input it recieves covariates `X`, treatment `T`, and a vector of factual outcomes `y` Note how `x` and `t` are concatenated for the input to network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJEk1fMPKYnD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def fit_model(x, y, t, seed):\n",
        "  setSeed(seed)\n",
        "  # concatenate the treatment and covariates\n",
        "  x_t = tf.concat([x, t], axis=1)\n",
        "  setSeed(seed)\n",
        "\n",
        "  model = SModel(name='slearner')\n",
        "  optimizer = Adam(learning_rate=1e-3)\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
        "  model.fit(x_t, y, epochs=300,\n",
        "            batch_size=64, validation_split=0.0,\n",
        "            verbose=1)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test = load_data(0)\n",
        "model = fit_model(data_train['x'], data_train['ys'], data_train['t'], seed=0)"
      ],
      "metadata": {
        "id": "V_NsAPu8NC_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7rN7aPkZN-I"
      },
      "source": [
        "**Change the learning rate, the number of layers and the number of hidden units (phi). Can you improve the reach an even smaller mse loss?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "def fit_model(x, y, t, seed):\n",
        "  setSeed(seed)\n",
        "  # concatenate the treatment and covariates\n",
        "  x_t = tf.concat([x, t], axis=1)\n",
        "  setSeed(seed)\n",
        "\n",
        "  model = SModel(name='slearner')\n",
        "  model.n_fc = ...\n",
        "  model.hidden_phi = ...\n",
        "  learning_rate = ...\n",
        "  optimizer = Adam(learning_rate= learning_rate)\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
        "  model.fit(x_t, y, epochs=300,\n",
        "            batch_size=64, validation_split=0.0,\n",
        "            verbose=1)\n",
        "  return model"
      ],
      "metadata": {
        "id": "eKP6a8paEkj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  data_train, data_test = load_data(0)\n",
        "  model = fit_model(data_train['x'], data_train['ys'], data_train['t'], seed=0)"
      ],
      "metadata": {
        "id": "4Tb2coQRHhYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1iTGfC_Z3Zo"
      },
      "source": [
        "# Estimating the ATE/CATE/ITE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP95mRFUq7AW"
      },
      "source": [
        "Now we can estimate causal effects for  a heldout testing sample.\n",
        "\n",
        "Although our ultimate goal is to estimate the $CATE$, our loss function only minimizes the factual error to estimate $\\hat{Y}$. This is a reflection of the fundamental problem of causal inference: we only observe one potential outcome for each unit. To get the quantities we want, we'll have to artificially toggle the treatment to get both $\\hat{y}(t)$ and $\\hat{y}(1-t)$ for each unit.\n",
        "\n",
        "We can then plug in our predictions $\\hat{Y}(0)$ and $\\hat{Y}(1)$ to calculate the predicted CATE as\n",
        "\n",
        "$$\\hat{CATE_i}=(1-2t_i)(\\hat{y_i}(t)-\\hat{y_i}(1-t))$$\n",
        "and the predicted average treatment effect as,\n",
        "$$\\hat{ATE}=\\frac{1}{n}\\sum_{i=1}^n\\hat{CATE_i}$$\n",
        "\n",
        "The true $CATE$s of IHDP dataset are known as they were simulated. Below is the most commonly used evaluation metrics in this literature.\n",
        "## Evaluation Metrics\n",
        "The most common metric in the literature to evaluate model performance on simulations is a squared root of Precision Estimation of Heterogeneous  Effects ($PEHE$) from [Hill, 2011](https://www.tandfonline.com/doi/abs/10.1198/jcgs.2010.08162?casa_token=b8-rfzagECIAAAAA:QeP7C4lKN6nZ7MkDjJHFrEberXopD9M5qPBMeBqbk84mI_8qGxj01ctgt4jdZtORpu9aZvpVRe07PA). $\\sqrt{PEHE}$ measures the error in estimates of the $CATE$: $$\\sqrt{PEHE}=\\sqrt{\\frac{1}{N}\\sum_{i=1}^N(CATE_i-\\hat{CATE_i})^2}$$\n",
        "\n",
        "Another popular metrics is $\\epsilon_{ATE} = |ATE-\\hat{ATE}|$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWw9IdRA3ncl"
      },
      "source": [
        "##TASK\n",
        "Fill in the gaps to estimate $\\sqrt{PEHE}$ and $\\epsilon_{ATE}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKovybfh3rwY"
      },
      "outputs": [],
      "source": [
        "def find_pehe(y0_pred, y1_pred, data):\n",
        "  \"\"\"\n",
        "  Calculates the PEHE and ATE metrics.\n",
        "\n",
        "  @param y0_pred: The predicted y0 values.\n",
        "  @param y1_pred: The predicted y1 values.\n",
        "  @param data: The data dictionary.\n",
        "\n",
        "  @return: A tuple containing two values: `sqrt_pehe` and `ate`.\n",
        "      `sqrt_pehe` is the square root of the PEHE metric,\n",
        "      `ate` is the absolute difference between the mean of the predicted CATE and the true ATE.\n",
        "  \"\"\"\n",
        "\n",
        "  y0_pred = data['y_scaler'].inverse_transform(y0_pred)\n",
        "  y1_pred = data['y_scaler'].inverse_transform(y1_pred)\n",
        "  # Fill in the gaps\n",
        "  cate_pred =  ...                            # note: you need to squeeze() the result\n",
        "  cate_true = ...\n",
        "  # compute the mean squared pehe using np.mean and np.square\n",
        "  pehe = ...\n",
        "  sqrt_pehe = np.sqrt(pehe)\n",
        "  ate = np.abs()\n",
        "  return sqrt_pehe, ate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzDma2Cw31s6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title SOLUTION\n",
        "def find_pehe(y0_pred, y1_pred, data):\n",
        "  \"\"\"\n",
        "  Calculates the PEHE and ATE metrics.\n",
        "\n",
        "  @param y0_pred: The predicted y0 values.\n",
        "  @param y1_pred: The predicted y1 values.\n",
        "  @param data: The data dictionary.\n",
        "\n",
        "  @return: A tuple containing two values: `sqrt_pehe` and `ate`.\n",
        "      `sqrt_pehe` is the square root of the PEHE metric,\n",
        "      `ate` is the absolute difference between the mean of the predicted CATE and the true ATE.\n",
        "  \"\"\"\n",
        "\n",
        "  y0_pred = data['y_scaler'].inverse_transform(y0_pred)\n",
        "  y1_pred = data['y_scaler'].inverse_transform(y1_pred)\n",
        "  # Fill in the gaps\n",
        "  cate_pred = (y1_pred - y0_pred).squeeze()\n",
        "  cate_true = (data['mu_1'] - data['mu_0']).squeeze()\n",
        "  pehe = np.mean(np.square((cate_true - cate_pred)))\n",
        "  sqrt_pehe = np.sqrt(pehe)\n",
        "  ate = np.abs(np.mean(cate_pred) - np.mean(cate_true))\n",
        "  return sqrt_pehe, ate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqXcKAdWqc0i"
      },
      "outputs": [],
      "source": [
        "def evaluate(x_test, model):\n",
        "    # To predict ITE with SLearner add zeros and ones to the X.\n",
        "    x_t0 = tf.concat([x_test, tf.zeros([x_test.shape[0], 1], dtype=tf.float64)], axis=1)\n",
        "    x_t1 = tf.concat([x_test, tf.ones([x_test.shape[0], 1], dtype=tf.float64)], axis=1)\n",
        "\n",
        "    out0 = model(x_t0)\n",
        "    out1 = model(x_t1)\n",
        "    return tf.concat((out0, out1), axis=1)\n",
        "\n",
        "\n",
        "concat_pred_test = evaluate(data_test['x'], model)\n",
        "# expand the dimensions\n",
        "y0_pred_test, y1_pred_test = concat_pred_test[:, 0], concat_pred_test[:, 1]\n",
        "y0_pred_test = tf.expand_dims(y0_pred_test, axis=1)\n",
        "y1_pred_test = tf.expand_dims(y1_pred_test, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XONNuICo4Bfy"
      },
      "source": [
        "Find the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMU0aBqV4FPF"
      },
      "outputs": [],
      "source": [
        "pehe_test, ate_test = find_pehe(y0_pred_test, y1_pred_test, data_test)\n",
        "print(0, 'Pehe Test = ', pehe_test, ' ATE test = ',  ate_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtkJCCCi7cPI"
      },
      "source": [
        "# Time to tune the hyperparameters of the *SLearner* and other models automatically. Connect to GPU runtime for faster execution. Can you see improvements in the results?\n",
        "\n",
        "Load the files again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po7c8pL0gJVU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# remove local directory if it already exists\n",
        "repo = \"Causal-Inference-Library\"\n",
        "if os.path.isdir(repo):\n",
        "    !rm -rf {repo}\n",
        "    # keep the latest version\n",
        "!git clone --depth=1 https://github.com/dyh1265/Causal-Inference-Library.git\n",
        "os.chdir('Causal-Inference-Library')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYGTdpKQREBU"
      },
      "outputs": [],
      "source": [
        "from main_hyper import *\n",
        "import keras_tuner as kt\n",
        "model_names = {\"TARnet\": TARnetHyper, \"TLearner\": TLearner, \"CFRNet\": CFRNet, \"SLearner\": SLearner, \"GNNTARnet\": GNNTARnetHyper}\n",
        "\n",
        "\n",
        "# Initialitze the parameters of a chosen model. For example, in case of a TARnet:\n",
        "model_name = \"GNNTARnet\"\n",
        "dataset_name = 'ihdp_a'\n",
        "ipm_type = 'wasserstein'\n",
        "\n",
        "params = find_params(model_name, dataset_name)\n",
        "params['model_name'] = model_name\n",
        "params['dataset_name'] = dataset_name\n",
        "params['ipm_type'] = ipm_type\n",
        "params['tuner_name'] = 'random'\n",
        "params['defaults'] = False\n",
        "params['cdm']  = 'lingam'\n",
        "params['num'] = 1\n",
        "params['verbose'] = 1\n",
        "params['tuner'] = kt.RandomSearch\n",
        "# get a class corresponding to the chosen model\n",
        "model = model_names[model_name]\n",
        "\n",
        "created_model = model(params)\n",
        "metric_list_train, metric_list_test, average_train, average_test  = created_model.evaluate_performance()\n",
        "m_test, h_test = mean_confidence_interval(metric_list_test, confidence=0.95)\n",
        "print(f'mean: {m_test} | std test: {h_test}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbv950lnCnMg"
      },
      "source": [
        "# Thank You!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rMuZFO_Ct3y"
      },
      "source": [
        "Thank you for participating in this workshop!\n",
        "\n",
        "In case your interested in using causal models for treatment effect estimation on your own data or you want to see how various models perform on different datasets - check out our library https://github.com/dyh1265/Causal-Inference-Library/\n",
        "\n",
        "Cheers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX66msriCsOW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "EB8rOrUnu2fR",
        "JgSdwi-ku7rT",
        "plnw_9HlY2t5"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}